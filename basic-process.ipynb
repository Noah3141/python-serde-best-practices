{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Serialization-Deserialization Type-Safe Automation\n",
    "\n",
    "##  Using ChatGPT and typing.TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserialization from sparse external JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Optional, Literal, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_json = \"\"\"\n",
    "{\n",
    "    \"name\": \"John Smith\",\n",
    "    \"age\": 32,\n",
    "    \"fan_of_olives\": true,\n",
    "    \"codes\": [\"321\", \"332\", \"442\", \"421\"]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the absence of any variety, we could assume that all fields are non-nullable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we cannot assume non-nullable, and do not have access to more objects, we should safe-access all fields, and implement default/fallback behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deserialization from plentiful external JSON\n",
    "\n",
    "In other cases, we have knowledge of the values of many instantiations of the object, through which the various data states (union types) can be detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "plentiful_json = \"\"\"\n",
    "[\n",
    "    {\n",
    "        \"name\": \"John Smith\",\n",
    "        \"age\": 32,\n",
    "        \"fan_of_olives\": true,\n",
    "        \"codes\": [\"321\", \"332\", \"442\", \"421\"]\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Jill Smith\",\n",
    "        \"age\": 30,\n",
    "        \"fan_of_olives\": true,\n",
    "        \"codes\": null\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Andrey Smith\",\n",
    "        \"fan_of_olives\": false,\n",
    "        \"codes\": [\"321\", \"332\", \"888\"]\n",
    "    },  \n",
    "    {\n",
    "        \"name\": \"Egor Kreed\",\n",
    "        \"fan_of_olives\": null,\n",
    "        \"codes\": null\n",
    "    }, \n",
    "    {\n",
    "        \"name\": \"Andrey Smith\",\n",
    "        \"fan_of_olives\": false,\n",
    "        \"codes\": [\"321\", \"332\", \"888\"]\n",
    "    }  \n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing the above JSON to ChatGPT with the prompt \"Generate a Python TypedDict out of this JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Person(TypedDict):\n",
    "#     name: str\n",
    "#     age: int\n",
    "#     fan_of_olives: Optional[bool]\n",
    "#     codes: Optional[List[str]]\n",
    " # GPT provides in the class syntax by default, but dictionary based representation has fewer representational translations, and is therefore more semantically direct\n",
    "\n",
    "Person = TypedDict(\"Person\", {\n",
    "    \"name\": str,\n",
    "    \"age\": int,\n",
    "    \"fan_of_olives\": Optional[bool],\n",
    "    \"codes\": Optional[List[str]],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, it recognizes two different forms of Option type:\n",
    "1. `Type | None` (in the case of 'codes')\n",
    "2. `boolean | None` (in the case of 'fan_of_olives', representing `True`, `False`, and `Unknown` states)\n",
    "\n",
    "It doesn't, however, do well at noticing that source JSON may sometimes *lack* a given key, see key `'age'`.\n",
    "\n",
    "In this case, an error possibility is left open:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " John Smith\n",
      "Codes:  ['321', '332', '442', '421']\n",
      "Fan of olives:  True\n",
      "Age:  32\n",
      "\n",
      " Jill Smith\n",
      "Codes:  None\n",
      "Fan of olives:  True\n",
      "Age:  30\n",
      "\n",
      " Andrey Smith\n",
      "Codes:  ['321', '332', '888']\n",
      "Fan of olives:  False\n",
      "❌Missing expected key: age!\n",
      "\n",
      " Egor Kreed\n",
      "Codes:  None\n",
      "Fan of olives:  None\n",
      "❌Missing expected key: age!\n",
      "\n",
      " Andrey Smith\n",
      "Codes:  ['321', '332', '888']\n",
      "Fan of olives:  False\n",
      "❌Missing expected key: age!\n"
     ]
    }
   ],
   "source": [
    "json_list: List[Person] = json.loads(plentiful_json);\n",
    "\n",
    "for obj in json_list:\n",
    "    print(\"\\n\", obj[\"name\"]) # Here we get autocomplete\n",
    "    try:\n",
    "        print(\"Codes: \", obj['codes'])\n",
    "    except:\n",
    "        print(\"❌Missing expected key: codes!\")\n",
    "\n",
    "    try:\n",
    "        print(\"Fan of olives: \", obj['fan_of_olives'])\n",
    "    except:\n",
    "        print(\"❌Missing expected key: fan_of_olives!\")\n",
    "\n",
    "    try:\n",
    "        print(\"Age: \", obj['age']) # Autocomplete offers 'age'\n",
    "    except:\n",
    "        print(\"❌Missing expected key: age!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that my claim here is based on nothing done at runtime. I am merely causing type-checking to take my word for it: \n",
    "```python \n",
    "    json_list: List[Person] = json.loads(plentiful_json);\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "If we build a class for the JSON object, we can express the underlying uncertainty more semantically by breaking out the two expectations:\n",
    "1. `TypedDict` states my expectation of the JSON structure\n",
    "2. `Class` states my expectation of being able to initialize a well-typed variable out of that JSON\n",
    "\n",
    "Or, put procedurally:\n",
    "1. Deserialize the JSON string to Python\n",
    "2. Make sure the Python variable generated matches my expectations -- upfront"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompting ChatGPT to \"Convert that TypedDict into a Python class whose __init__ method takes only the parameter `json_data: TypedDict`\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Person = TypedDict(\"Person\", {\n",
    "    \"name\": str,\n",
    "    \"age\": int, # Inaccurate assumption of required presence\n",
    "    \"fan_of_olives\": Optional[bool],\n",
    "    \"codes\": Optional[List[str]],\n",
    "})\n",
    "\n",
    "class PersonClass:\n",
    "    def __init__(self, json_data: Person): # Autocomplete from here according to expectation declared above\n",
    "        self.name = json_data['name']\n",
    "        self.age = json_data[\"age\"]\n",
    "        self.fan_of_olives = json_data['fan_of_olives']\n",
    "        self.codes = json_data['codes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When my expectation of being able to initialize a known-typed object out of the JSON fails, I then realize that my expectation of the JSON itself needs updating. Once that is done, type checking will propogate those implications for me.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " John Smith\n",
      "Codes:  ['321', '332', '442', '421']\n",
      "Fan of olives:  True\n",
      "Age:  32\n",
      "\n",
      " Jill Smith\n",
      "Codes:  None\n",
      "Fan of olives:  True\n",
      "Age:  30\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m json_list \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(plentiful_json);\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m json_list:\n\u001b[1;32m----> 4\u001b[0m     person \u001b[38;5;241m=\u001b[39m \u001b[43mPersonClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# dot access completion:\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, person\u001b[38;5;241m.\u001b[39mname)\n",
      "Cell \u001b[1;32mIn[29], line 11\u001b[0m, in \u001b[0;36mPersonClass.__init__\u001b[1;34m(self, json_data)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, json_data: Person):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mage \u001b[38;5;241m=\u001b[39m \u001b[43mjson_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfan_of_olives \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfan_of_olives\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodes \u001b[38;5;241m=\u001b[39m json_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "json_list = json.loads(plentiful_json);\n",
    "\n",
    "for obj in json_list:\n",
    "    person = PersonClass(obj)\n",
    "\n",
    "    # dot access completion:\n",
    "    print(\"\\n\", person.name)\n",
    "    print(\"Codes: \", person.codes)\n",
    "    print(\"Fan of olives: \", person.fan_of_olives)\n",
    "    print(\"Age: \", person.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having automatically generated the TypedDict and its corresponding class in under a minute, we can easily funnel the JSON list through this kind of test, whereupon we can progressively adjust our expectations of the source JSON, when keys reveal themselves to be conditionally present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NotRequired\n",
    "\n",
    "Person = TypedDict(\"Person\", {\n",
    "    \"name\": str,\n",
    "    \"age\": NotRequired[int], # Fixed based on quick test\n",
    "    \"fan_of_olives\": Optional[bool],\n",
    "    \"codes\": Optional[List[str]],\n",
    "})\n",
    "\n",
    "class PersonClass:\n",
    "    def __init__(self, json_data: Person): # Autocomplete from here according to expectation declared above\n",
    "        self.name = json_data['name']\n",
    "        self.age = json_data[\"age\"] # Pylance now understands that this is unsafe through the `reportTypedDictNotRequiredAccess` setting\n",
    "        self.fan_of_olives = json_data['fan_of_olives']\n",
    "        self.codes = json_data['codes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the declaration of the expectations for the source JSON is explicitly denoting the unreliable presence of the key. This propogates type-check errors into the class, where we can then explicitly handle the conditionaly presence of the value, either by implementing a simple default, or a fallback behavior (raising an exception, getting the value from an API, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonClass:\n",
    "    def __init__(self, json_data: Person): # Autocomplete from here according to expectation declared above\n",
    "        self.name = json_data['name']\n",
    "        self.age = json_data.get('age', None)\n",
    "        self.fan_of_olives = json_data['fan_of_olives']\n",
    "        self.codes = json_data['codes']\n",
    "\n",
    "# JSON lacking the age key\n",
    "person = PersonClass({\n",
    "    'codes': None,\n",
    "    'fan_of_olives': False,\n",
    "    'name': \"Jim Henson\"\n",
    "})\n",
    "\n",
    "# Type checking pulls from the class' types, which implement the recovery behavior we added to the class\n",
    "# In this case, `int | None`\n",
    "age = person.age \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better than simply marking the whole TypedDict with `total=False`, which globally claims that the dictionary may or may not have any given key, while maintaining that if the key is present, its value is of the stated type. That option would force us to claim that any field may conditionally absent, which is `untrue`, semantically misleading, and leads to a preponderance of not-actually-needed null checking or default-value confabulation.\n",
    "\n",
    "By the targeted application of `NotRequired`, assuming we have a representative sample of the source JSON's variability, we can pinpoint those fields which actually need a fallback, without compromising the convenience of straightforward typing and access of truly required fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also necessary to create a separation of JSON expectation from Python translation anyway, because fields may need post-processing, such as turning a string into a datetime object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
